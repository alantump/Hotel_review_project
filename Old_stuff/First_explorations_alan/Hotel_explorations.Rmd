---
title: "Hotel_exploration"
author: "Alan"
date: "2024-10-19"
output: html_document
---

```{r setup, include=FALSE}
library(dplyr)
library(brms)
library(ggplot2)
library(lme4)
library(lubridate)
library(stringr)
library(cowplot)
library(shiny)
```

## R Markdown


```{r cars}
shiny_t = F #load shiny stuff?
source("functions.R")

Hotel_Reviews <- data_loader()


# Filter hotels with at least 500 reviews
Hotel_Reviews <- Hotel_Reviews %>%
  group_by(Hotel_Name) %>%
  filter(n() >= 500) %>%
  ungroup()


```
Base data
```{r}
dim(Hotel_Reviews)
length(unique(Hotel_Reviews$Hotel_Name))
```



```{r}
trip_time = 356 #day 
trip_start = max(Hotel_Reviews$date_object)-trip_time 
booking_time = trip_start
attention_window = 356 


Hotel_Reviews = Hotel_Reviews %>% mutate(time_ref = as.numeric(date_object- booking_time)/30.5)

train_data = Hotel_Reviews %>% filter(date_object < booking_time &
                                            date_object > (booking_time-attention_window) )


test_data = Hotel_Reviews %>% filter(date_object > trip_start &
                                            date_object < (trip_start+trip_time) )
```


```{r}



dummy = Hotel_Reviews %>% filter( date_object > (booking_time-attention_window) ) %>% mutate(group = ifelse(date_object > trip_start,"after", "before"))



fit = lm(
   Reviewer_Score ~ 0 +  Hotel_Name * group:Hotel_Name, data = dummy)

```



```{r pressure}

all_coefficients = coef(fit)
model_summary <- summary(fit)
#fit = strip_lm(fit)


t_threshold =  qt(0.8,Inf)



# Extract the coefficients table
coefficients_table <- model_summary$coefficients

# Extract only the interaction terms
interaction_summary <- coefficients_table[grep(":", rownames(coefficients_table)), ]


 time_effct = data.frame(interaction_summary) %>% mutate(Name= rownames(.),
                                                         Name = stringr::str_replace(Name, c("Hotel_Name"),""),
                                                         Name = stringr::str_replace(Name, c(":time_ref"),"")) %>%
   arrange(Estimate) %>%
  mutate(Name = factor(Name, levels = Name)) %>% mutate(Pos = ifelse(t.value>t_threshold, 1, 0),
                                                        Neg = ifelse(t.value<(-t_threshold), 1, 0),
                                                        tendency = Pos-Neg) 

 
 time_effct %>% ggplot(aes(x=Name, y= Estimate, colour = as.factor(tendency))) + geom_point() +
   geom_pointrange(aes(ymin = Estimate - (Std..Error*2) ,ymax= Estimate + (Std..Error*2)),alpha=0.2) + 
   coord_flip() + geom_hline(yintercept = 0) + theme(legend.position = "None") +
   scale_color_manual(values=c("#F8766D", "#56B4E9", "#7CAE00")) + 
  annotate("text", x = Inf, y = Inf, label = paste("Positive trend:", round(mean(time_effct$Pos), 2)), hjust = 1, vjust = 2+3, size = 4, color = "#7CAE00") +
  annotate("text", x = Inf, y = Inf, label = paste("No clear trend:", round(mean(time_effct$tendency==0), 2)), hjust = 1, vjust = 3.5+3, size = 4, color = "#56B4E9") +
  annotate("text", x = Inf, y = Inf, label = paste("Negative trend:", round(mean(time_effct$Neg), 2)), hjust = 1, vjust = 5+3, size = 4, color = "#F8766D") 

 


```



```{r pressure}
fit = lm(
   Reviewer_Score ~ 0 +  Hotel_Name + time_ref:Hotel_Name, data = train_data)
#save(fit, file = "Simple_lm.RData")
all_coefficients = coef(fit)
model_summary <- summary(fit)
#fit = strip_lm(fit)

#load(file = "Simple_lm.RData")
```



```{r}

t_threshold =  qt(0.8,Inf)



# Extract the coefficients table
coefficients_table <- model_summary$coefficients

# Extract only the interaction terms
interaction_summary <- coefficients_table[grep(":", rownames(coefficients_table)), ]


 time_effct = data.frame(interaction_summary) %>% mutate(Name= rownames(.),
                                                         Name = stringr::str_replace(Name, c("Hotel_Name"),""),
                                                         Name = stringr::str_replace(Name, c(":time_ref"),"")) %>%
   arrange(Estimate) %>%
  mutate(Name = factor(Name, levels = Name)) %>% mutate(Pos = ifelse(t.value>t_threshold, 1, 0),
                                                        Neg = ifelse(t.value<(-t_threshold), 1, 0),
                                                        tendency = Pos-Neg) 

 
 time_effct %>% ggplot(aes(x=Name, y= Estimate, colour = as.factor(tendency))) + geom_point() +
   geom_pointrange(aes(ymin = Estimate - (Std..Error*2) ,ymax= Estimate + (Std..Error*2)),alpha=0.2) + 
   coord_flip() + geom_hline(yintercept = 0) + theme(legend.position = "None") +
   scale_color_manual(values=c("#F8766D", "#56B4E9", "#7CAE00")) + 
  annotate("text", x = Inf, y = Inf, label = paste("Positive trend:", round(mean(time_effct$Pos), 2)), hjust = 1, vjust = 2+3, size = 4, color = "#7CAE00") +
  annotate("text", x = Inf, y = Inf, label = paste("No clear trend:", round(mean(time_effct$tendency==0), 2)), hjust = 1, vjust = 3.5+3, size = 4, color = "#56B4E9") +
  annotate("text", x = Inf, y = Inf, label = paste("Negative trend:", round(mean(time_effct$Neg), 2)), hjust = 1, vjust = 5+3, size = 4, color = "#F8766D") 

 
 
 
 
```


# Predictive performance

```{r}


train_data2 = train_data
train_data2$Estimate = predict(fit, newdata = train_data )



rmse = sqrt(mean((train_data2$Estimate - train_data$Reviewer_Score)^2))
ame = (mean(abs(train_data2$Estimate - train_data$Reviewer_Score)))
cat(paste0("Insample:\nAbsolute error: ", ame,
             "\nRMSE: ",rmse))
 

test_data2 = test_data %>% filter(Hotel_Name %in% unique(train_data2$Hotel_Name))
test_data2$Estimate = predict(fit, newdata = test_data2)

rmse = sqrt(mean((test_data2$Estimate - test_data2$Reviewer_Score)^2))
ame = (mean(abs(test_data2$Estimate - test_data2$Reviewer_Score)))
rmse_ho = sqrt(mean((test_data2$Average_Score - test_data2$Reviewer_Score)^2))
ame_ho = mean(abs(test_data2$Average_Score - test_data2$Reviewer_Score))
cat(paste0("\nPrediction:\nAbsolute error: ", ame, " vs. H0- ",ame_ho,
             "\nRMSE: ",rmse, "vs. H0- ",rmse_ho))

```
```{r}
 past_average <- Hotel_Reviews %>% filter(time_ref<0) %>% group_by(Hotel_Name) %>% summarise(past_average = mean(Reviewer_Score))

grouped_test_data <- test_data2 %>% group_by(Hotel_Name) %>% summarise(mean_review = mean(Reviewer_Score)) %>%
  left_join(time_effct %>% mutate(Hotel_Name=Name), by = "Hotel_Name") %>%
    left_join(past_average, by = "Hotel_Name") %>% mutate(correct_neg = past_average>mean_review, correct_pos = past_average<mean_review  )

 grouped_test_data %>% group_by(Neg) %>% summarise(m = mean(correct_neg))
 grouped_test_data %>% group_by(Pos) %>% summarise(m = mean(correct_pos))





proportion_data_neg <- grouped_test_data %>%
  group_by(Neg, correct_neg) %>%
  summarise(m = length(Hotel_Name)) %>%
  ungroup() %>%
  mutate(proportion = m / sum(m))



proportion_data_pos <- grouped_test_data %>%
  group_by(Pos, correct_pos) %>%
  summarise(m = length(Hotel_Name)) %>%
  ungroup() %>%
  mutate(proportion = m / sum(m))


# Calculate Recall and F1 Score
true_positive <- proportion_data_neg %>% filter(Neg == 1, correct_neg == 1) %>% pull(m)
false_negative <- proportion_data_neg %>% filter(Neg == 0, correct_neg == 1) %>% pull(m)
false_positive <- proportion_data_neg %>% filter(Neg == 1, correct_neg == 0) %>% pull(m)

recall_neg <- true_positive / (true_positive + false_negative)
precision_neg <- true_positive / (true_positive + false_positive)
f1_score_neg <- 2 * (precision_neg * recall_neg) / (precision_neg + recall_neg)


# Calculate Recall and F1 Score
true_positive <- proportion_data_pos %>% filter(Pos == 1, correct_pos == 1) %>% pull(m)
false_Posative <- proportion_data_pos %>% filter(Pos == 0, correct_pos == 1) %>% pull(m)
false_positive <- proportion_data_pos %>% filter(Pos == 1, correct_pos == 0) %>% pull(m)

recall_pos <- true_positive / (true_positive + false_negative)
precision_pos <- true_positive / (true_positive + false_positive)
f1_score_pos <- 2 * (precision_pos * recall_pos) / (precision_pos + recall_pos)


# Plot the proportions as a 2x2 matrix
plot_grid(ggplot(proportion_data_neg, aes(y = factor(Neg), x = factor(correct_neg), fill = proportion)) +
  geom_tile() +
  geom_text(aes(label = round(proportion, 2)), color = "black") +
  scale_fill_gradient(low = "white", high = "darkred") +
  theme_minimal() +
  labs(x = "Reviews being worse than past average", y = "Detoration detection", fill = "Proportion") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  annotate("text", x = 1.5, y = 2.4, label = paste("Recall:", round(recall_neg, 2)), size = 4, color = "black") +
  annotate("text", x = 1.5, y = 2.3, label = paste("Precision:", round(precision_neg, 2)), size = 4, color = "black") +
  annotate("text", x = 1.5, y = 2.2, label = paste("F1 Score:", round(f1_score_neg, 2)), size = 4, color = "black"),
  ggplot(proportion_data_pos, aes(y = factor(Pos), x = factor(correct_pos), fill = proportion)) +
  geom_tile() +
  geom_text(aes(label = round(proportion, 2)), color = "black") +
  scale_fill_gradient(low = "white", high = "darkgreen") +
  theme_minimal() +
  labs(x = "Reviews being better than past average", y = "Imporvement detection", fill = "Proportion") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  annotate("text", x = 1.5, y = 2.4, label = paste("Recall:", round(recall_pos, 2)), size = 4, color = "black") +
  annotate("text", x = 1.5, y = 2.3, label = paste("Precision:", round(precision_pos, 2)), size = 4, color = "black") +
  annotate("text", x = 1.5, y = 2.2, label = paste("F1 Score:", round(f1_score_pos, 2)), size = 4, color = "black"))


```



```{r}



# Define UI
ui <- fluidPage(
  mainPanel(
    sliderInput("Sensetivity", "Sensetivity:", min = 0, max=1, step =0.05, value=0.1),
    plotOutput("distPlot", height = "600px")
  )
)


server <- function(input, output) {
  output$distPlot <- renderPlot({
    
    t_threshold <- qt(1-input$Sensetivity/2,Inf)
    

 
all_coefficients = coef(fit)
model_summary <- summary(fit)

# Extract the coefficients table
coefficients_table <- model_summary$coefficients

# Extract only the interaction terms
interaction_summary <- coefficients_table[grep(":", rownames(coefficients_table)), ]


 time_effct = data.frame(interaction_summary) %>% mutate(Name= rownames(.),
                                                         Name = stringr::str_replace(Name, c("Hotel_Name"),""),
                                                         Name = stringr::str_replace(Name, c(":time_ref"),"")) %>%
   arrange(Estimate) %>%
  mutate(Name = factor(Name, levels = Name)) %>% mutate(Pos = ifelse(t.value>t_threshold, 1, 0),
                                                        Neg = ifelse(t.value<(-t_threshold), 1, 0),
                                                        tendency = Pos-Neg) 

 
 p1 = 
 time_effct %>% ggplot(aes(x=Name, y= Estimate, colour = as.factor(tendency))) + geom_point() +
   geom_pointrange(aes(ymin = Estimate - (Std..Error*2) ,ymax= Estimate + (Std..Error*2)),alpha=0.2) + 
   coord_flip() + geom_hline(yintercept = 0) + theme(legend.position = "None") +
   scale_color_manual(values=c("#F8766D", "#56B4E9", "#7CAE00")) + 
  annotate("text", x = Inf, y = Inf, label = paste("Positive trend:", round(mean(time_effct$Pos), 2)), hjust = 1, vjust = 2+3, size = 4, color = "#7CAE00") +
  annotate("text", x = Inf, y = Inf, label = paste("No clear trend:", round(mean(time_effct$tendency==0), 2)), hjust = 1, vjust = 3.5+3, size = 4, color = "#56B4E9") +
  annotate("text", x = Inf, y = Inf, label = paste("Negative trend:", round(mean(time_effct$Neg), 2)), hjust = 1, vjust = 5+3, size = 4, color = "#F8766D") 

 
 past_average <- Hotel_Reviews %>% filter(time_ref<0) %>% group_by(Hotel_Name) %>% summarise(past_average = mean(Reviewer_Score))

grouped_test_data <- test_data2 %>% group_by(Hotel_Name) %>% summarise(mean_review = mean(Reviewer_Score)) %>%
  left_join(time_effct %>% mutate(Hotel_Name=Name), by = "Hotel_Name") %>%
    left_join(past_average, by = "Hotel_Name") %>% mutate(correct_neg = past_average>mean_review, correct_pos = past_average<mean_review  )

 grouped_test_data %>% group_by(Neg) %>% summarise(m = mean(correct_neg))
 grouped_test_data %>% group_by(Pos) %>% summarise(m = mean(correct_pos))





proportion_data_neg <- grouped_test_data %>%
  group_by(Neg, correct_neg) %>%
  summarise(m = length(Hotel_Name)) %>%
  ungroup() %>%
  mutate(proportion = m / sum(m))



proportion_data_pos <- grouped_test_data %>%
  group_by(Pos, correct_pos) %>%
  summarise(m = length(Hotel_Name)) %>%
  ungroup() %>%
  mutate(proportion = m / sum(m))


# Calculate Recall and F1 Score
true_positive <- proportion_data_neg %>% filter(Neg == 1, correct_neg == 1) %>% pull(m)
false_negative <- proportion_data_neg %>% filter(Neg == 0, correct_neg == 1) %>% pull(m)
false_positive <- proportion_data_neg %>% filter(Neg == 1, correct_neg == 0) %>% pull(m)

recall_neg <- true_positive / (true_positive + false_negative)
precision_neg <- true_positive / (true_positive + false_positive)
f1_score_neg <- 2 * (precision_neg * recall_neg) / (precision_neg + recall_neg)


# Calculate Recall and F1 Score
true_positive <- proportion_data_pos %>% filter(Pos == 1, correct_pos == 1) %>% pull(m)
false_Posative <- proportion_data_pos %>% filter(Pos == 0, correct_pos == 1) %>% pull(m)
false_positive <- proportion_data_pos %>% filter(Pos == 1, correct_pos == 0) %>% pull(m)

recall_pos <- true_positive / (true_positive + false_negative)
precision_pos <- true_positive / (true_positive + false_positive)
f1_score_pos <- 2 * (precision_pos * recall_pos) / (precision_pos + recall_pos)


# Plot the proportions as a 2x2 matrix
plot_grid(p1,plot_grid(ggplot(proportion_data_neg, aes(y = factor(Neg), x = factor(correct_neg), fill = proportion)) +
  geom_tile() +
  geom_text(aes(label = round(proportion, 2)), color = "black") +
  scale_fill_gradient(low = "white", high = "darkred") +
  theme_minimal() +
  labs(x = "Reviews being worse than past average", y = "Detoration detection", fill = "Proportion") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  annotate("text", x = 1.5, y = 2.4, label = paste("Recall:", round(recall_neg, 2)), size = 4, color = "black") +
  annotate("text", x = 1.5, y = 2.3, label = paste("Precision:", round(precision_neg, 2)), size = 4, color = "black") +
  annotate("text", x = 1.5, y = 2.2, label = paste("F1 Score:", round(f1_score_neg, 2)), size = 4, color = "black"),
  ggplot(proportion_data_pos, aes(y = factor(Pos), x = factor(correct_pos), fill = proportion)) +
  geom_tile() +
  geom_text(aes(label = round(proportion, 2)), color = "black") +
  scale_fill_gradient(low = "white", high = "darkgreen") +
  theme_minimal() +
  labs(x = "Reviews being better than past average", y = "Imporvement detection", fill = "Proportion") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  annotate("text", x = 1.5, y = 2.4, label = paste("Recall:", round(recall_pos, 2)), size = 4, color = "black") +
  annotate("text", x = 1.5, y = 2.3, label = paste("Precision:", round(precision_pos, 2)), size = 4, color = "black") +
  annotate("text", x = 1.5, y = 2.2, label = paste("F1 Score:", round(f1_score_pos, 2)), size = 4, color = "black")), ncol=1)

  })
}


 shinyApp(ui = ui, server = server)

 
```




```{r}

library(shiny)
library(DT)


test_window = expand.grid(Hotel_Name = unique(test_data$Hotel_Name), time_ref = seq(min(train_data$time_ref), max(test_data$time_ref),0.2), Reviewer_Score2 =NA)
#train_data2 = train_data2 %>% mutate(Estimate = NA)
train_data2 = train_data2 %>% mutate(Reviewer_Score2 = Reviewer_Score)
test_window$Estimate = predict(fit, newdata = test_window)


plot_data = train_data2

hotel_names <- unique(plot_data$Hotel_Name)
```

```{r}



# Define UI
ui <- fluidPage(
  mainPanel(
    selectInput("hotel", "Select Hotel:", choices = hotel_names),
    plotOutput("distPlot")
  )
)

# Define server logic
server <- function(input, output) {
  output$distPlot <- renderPlot({
    
    selected_hotel <- input$hotel
    
    # Filter data for the selected hotel
    filtered_data <- plot_data %>% filter(Hotel_Name == selected_hotel)
    
    
    # Check if the selected hotel has Neg == TRUE
    neg_hotel <- random_effct2 %>% filter(Name == selected_hotel & Neg == TRUE)

    
    # Plot
   p =  ggplot(filtered_data, aes(x = time_ref, y = Reviewer_Score2)) +
      geom_line(aes(y = Average_Score), color = "gray") +
      geom_point(aes(x = time_ref, y = Reviewer_Score2), alpha = 0.5) +
      geom_smooth(aes(x = time_ref, y = Reviewer_Score2), lty = "dashed") +
      geom_line(data= test_window  %>% filter(Hotel_Name == selected_hotel), aes(x=time_ref, y=Estimate)) +
      labs(title = "Predicted Reviewer Scores Over Time",
           x = "Date",
           y = "Predicted Reviewer Score") +
      coord_cartesian(ylim = c(6, 10)) + 
      theme_minimal() + 
      theme(legend.position = c(0.5, 0.9))
   if(random_effct2$Neg[random_effct2$Name == selected_hotel]==1)p =  p + geom_text(data = neg_hotel, aes(x = max(filtered_data$time_ref), y = 9, label = "!"), size = 10, color = "red", vjust = -1)
   if(random_effct2$Pos[random_effct2$Name == selected_hotel] ==1) p =  p + geom_text(data = neg_hotel, aes(x = max(filtered_data$time_ref), y = 9, label = "+"), size = 10, color = "green", vjust = -1)
   plot_grid(p,
   
   rbind(test_window  %>% filter(Hotel_Name == selected_hotel, time_ref > 0) %>% group_by(Hotel_Name) %>% summarise(pred = mean(Estimate), type="Prediction"),
   test_data  %>% filter(Hotel_Name == selected_hotel, time_ref > 0) %>% group_by(Hotel_Name) %>% summarise(pred = mean(Reviewer_Score), type="Vacation average"),
   Hotel_Reviews  %>% filter(Hotel_Name == selected_hotel, time_ref < 0) %>% group_by(Hotel_Name) %>% summarise(pred = mean(Reviewer_Score), type="Past average")) %>%
     ggplot(aes(x=type, y=pred)) + geom_bar(stat="identity") +      coord_cartesian(ylim = c(7, 10))  
   )


  })
}



shinyApp(ui = ui, server = server)

```

```{r}

```



```{r}
library(caret)


# Load libraries
library(tm)
library(caret)

# Sample data
# Assuming Hotel_Reviews is your data frame
# Hotel_Reviews <- read.csv("your_data.csv")

# Create a Corpus
corpus <- Corpus(VectorSource(Hotel_Reviews$Negative_Review))

# Text preprocessing
corpus <- tm_map(corpus, content_transformer(tolower))
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, removeNumbers)
corpus <- tm_map(corpus, removeWords, stopwords("en"))
corpus <- tm_map(corpus, stripWhitespace)

dtm <- DocumentTermMatrix(corpus, control = list(wordLengths = c(1, Inf)))

freq_terms <- findFreqTerms(dtm, lowfreq = 10)

dtm <- DocumentTermMatrix(corpus, control = list(dictionary = freq_terms))


# Convert DTM to TF-IDF
tfidf <- weightTfIdf(dtm)



# Convert to a data frame
tfidf_df <- as.data.frame(as.matrix(tfidf))




# Convert to a data frame
dtm_df <- as.data.frame(as.matrix(dtm_top))


model <- train(Class ~ ., data = trainData, method = "rf")


```

```{r}
library(tidyverse) # mainly dplyr
library(udpipe)    # tokenization & lemmatization
library(caret)     # used to split the dataset to train / test
library(keras)     # because Keras :)



# directory for source data files
network_path <- 'http://www.jla-data.net/ENG/2019-01-25-vocabulary-based-text-classification_files/'

tf_tweets <- tempfile(fileext = ".csv") # create a temporary csv file
download.file(paste0(network_path, 'tidy_tweets.csv'), tf_tweets, quiet = T)
tweets <- read.csv(tf_tweets, stringsAsFactors = F) # read the tweet data in

# download current udpipe model for English
udtarget <- udpipe_download_model(language = "english",
                                  model_dir = tempdir())
# load the model
udmodel <- udpipe_load_model(file = udtarget$file_model) 

table(tweets$name) # verify structure of downloaded tweets


words <- udpipe_annotate(udmodel, x = tweets$text, doc_id = tweets$id) %>% 
  as.data.frame() %>%
  select(id = doc_id, token, lemma, upos, sentence_id) %>%
  mutate(id = as.numeric(id))

vocabulary <- words %>%
  count(lemma) %>%
  ungroup() %>%
  arrange(desc(n)) %>%
  filter(n >=3) %>%  # little predictive value in rare words
  mutate(id_slovo = row_number()) %>% # unique id per lemma
  select(lemma, id_slovo)

# a sneak peak at the vocabulary object
glimpse(vocabulary)
```


```{r}
# 150 zeroes for each tweet id for padding
vata <- expand.grid(id = unique(words$id),
                    word_num = 1:150,
                    id_slovo = 0)

word_matrix <- words %>% # words
  # filtering join! words not in vocabulary are discarded
  inner_join(vocabulary, by = c('lemma' = 'lemma')) %>% 
  select(id, lemma, id_slovo) %>%
  group_by(id) %>%
  mutate(word_num = row_number()) %>% # 
  ungroup() %>%
  select(id, word_num, id_slovo) %>% # relevant columns
  rbind(vata) %>% # bind the 150 zeroes per tweet
  group_by(id, word_num) %>%
  mutate(id_slovo = max(id_slovo)) %>% # will include duplicites
  ungroup() %>%
  unique() %>% # remove duplicites
  spread(word_num, id_slovo) # spread to matrix format

keras_input <- tweets %>%
  select(id, name, text) %>%
  inner_join(word_matrix, by = c('id' = 'id'))

set.seed(42) # Zaphod Beeblebrox advises to trust no other!

idx <- createDataPartition(keras_input$name, p = .8, list = F, times = 1) # 80 / 20 split

train_data <- keras_input[idx, ] # train dataset
test_data <- keras_input[-idx, ] # verification```
```


```{r}
train_data <- train_data %>%
  mutate(hadley = ifelse(name == 'hadleywickham', 1,0)) %>% # binary output
  select(-id, -name, -text)

x_train <- data.matrix(train_data %>% select(-hadley)) # everything except target
y_train <- data.matrix(train_data %>% select(hadley)) # target, and target only

vocab_size <- vocabulary %>% # count unique word ids
  pull(id_slovo) %>% 
  unique() %>%
  length() + 1 # one extra for the zero padding


model <- keras_model_sequential() 

model %>% 
  layer_embedding(input_dim = vocab_size, output_dim = 256) %>%
  bidirectional(layer_lstm(units = 128)) %>%
  layer_dropout(rate = 0.5) %>% 
  layer_dense(units = 1, activation = 'sigmoid') # 1 = Hadley, 0 = Marie

model %>% 
  compile(optimizer = "rmsprop",
          loss = "binary_crossentropy",
          metrics = c("accuracy"))

history <- model %>%  # fit the model (this will take a while...)
  fit(x_train, 
      y_train, 
      epochs = 25, 
      batch_size = nrow(train_data)/5, 
      validation_split = 1/5)

summary(model)

```

