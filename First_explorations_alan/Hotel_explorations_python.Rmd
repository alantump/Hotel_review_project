---
title: "Hotel_exploration_python"
author: "Alan"
date: "2024-10-19"
output: html_document
---

```{python setup, include=FALSE}


```

## R Markdown


```{python cars}
import numpy as np
import pandas as pd
import re  # for regular expression matching

def data_loader():
  """Loads data from CSV files, performs data cleaning and feature engineering.

  Returns:
    pandas.DataFrame: The processed hotel reviews dataset.
  """

  # Read hotel reviews data
  Hotel_Reviews = pd.read_csv("../Data/Hotel_Reviews.csv")

  # Read country data
  countries = pd.read_csv("../Data/countries.csv")

  # Add a "Country" column with NA values
  Hotel_Reviews["Country"] = pd.NA

  # Assign country based on pattern matching in Hotel_Address
  for country_name in countries["name"]:
    pattern = re.compile(country_name, re.IGNORECASE)  # Case-insensitive matching
    Hotel_Reviews.loc[Hotel_Reviews["Hotel_Address"].str.contains(pattern), "Country"] = country_name

 
  # Convert Review_Date to datetime and extract features
  Hotel_Reviews["date_object"] = pd.to_datetime(Hotel_Reviews["Review_Date"], format="%m/%d/%Y")
  #Hotel_Reviews["time"] = Hotel_Reviews["date_object"].astype(int) / 10**9  # Convert to Unix timestamp
  Hotel_Reviews["month"] = Hotel_Reviews["date_object"].dt.month
  Hotel_Reviews["num_date_object"] = Hotel_Reviews["date_object"].dt.day_of_year / 365  # Normalize by days in a year

  return Hotel_Reviews

# Load the processed data
Hotel_Reviews = data_loader()

```

```{python}
print(Hotel_Reviews.shape)
print(Hotel_Reviews["Hotel_Name"].nunique())
```


```{python}




# Calculate trip time and start date
trip_time = 31 * 3
trip_start = Hotel_Reviews["date_object"].max() - pd.Timedelta(days=trip_time)
booking_time = trip_start
attention_window = 356 * 1.5

# Calculate time reference
Hotel_Reviews["time_ref"] = (Hotel_Reviews["date_object"] - booking_time).dt.days / 30.5

# Filter detection and test data
detection_data = Hotel_Reviews[(Hotel_Reviews["date_object"] < booking_time) &
                               (Hotel_Reviews["date_object"] > (booking_time - pd.Timedelta(days=attention_window)))]

test_data = Hotel_Reviews[(Hotel_Reviews["date_object"] > trip_start) &
                           (Hotel_Reviews["date_object"] < (trip_start + pd.Timedelta(days=trip_time)))]

```






```{python pressure}

import statsmodels.api as sm


model = sm.OLS.from_formula(
    "Reviewer_Score ~ 0 + Hotel_Name + time_ref:Hotel_Name",
    data=Hotel_Reviews
).fit()

model.save("simple_lm.pickle")

```

```{python}
import matplotlib.pyplot as plt
import scipy.stats as stats

# Extract interaction coefficients

#interaction_terms = model.params[model.params.index.str.contains(":")]



# Create a DataFrame for interaction effects
time_effect_df = pd.DataFrame(model.params, columns=["Estimate"])
time_effect_df.index.name = "Name"
time_effect_df.reset_index(inplace=True)

# Extract hotel names and calculate t-statistics
time_effect_df["Hotel_Name"] = time_effect_df["Name"].str.extract(r"\[(.*?)\]")
time_effect_df["t_value"] = time_effect_df.index.map(lambda x: model.tvalues.iloc[x])
time_effect_df["Std.Error"] = time_effect_df.index.map(lambda x: model.bse.iloc[x])

time_effect_df = time_effect_df[model.params.index.str.contains(":")]

# Calculate significance threshold
t_threshold = stats.t.ppf(0.90, df=model.df_resid)

# Determine significance and direction
time_effect_df["Pos"] = (time_effect_df["t_value"] > t_threshold).astype(int)
time_effect_df["Neg"] = (time_effect_df["t_value"] < -t_threshold).astype(int)
time_effect_df["tendency"] = time_effect_df["Pos"] - time_effect_df["Neg"]

# Sort by estimate and plot
time_effect_df.sort_values("Estimate", inplace=True)

plt.figure(figsize=(10, 6))
# Remove the horizontal line
errorbar_colors = time_effect_df["tendency"].map({-1: "red", 0: "gray", 1: "blue"})
plt.errorbar(time_effect_df.index, time_effect_df["Estimate"], yerr=time_effect_df["Std.Error"], fmt='none', ecolor=errorbar_colors, capsize=5)
#plt.hlines(0, xmin=-1, xmax=len(time_effect_df), colors='gray', linestyles='--')
plt.scatter(time_effect_df.index, time_effect_df["Estimate"], c=time_effect_df["tendency"].map({-1: "red", 0: "gray", 1: "blue"}))
plt.xticks(time_effect_df.index, time_effect_df["Hotel_Name"], rotation=45, ha='right')
plt.ylabel("Estimate")
plt.title("Time Effect by Hotel")

# Add text annotations
mean_pos = time_effect_df["Pos"].mean()
mean_neg = time_effect_df["Neg"].mean()
plt.text(x=len(time_effect_df) + 0.5, y=0.1, s=f"Mean Pos: {mean_pos:.2f}", fontsize=12, color="blue")
plt.text(x=len(time_effect_df) + 0.5, y=-0.1, s=f"Mean Neg: {mean_neg:.2f}", fontsize=12, color="red")

plt.show()


 
 
sorted = time_effect_df.sort_values("Estimate").reset_index(drop=True)
 
 
plt.figure(figsize=(10, 6))
# Remove the horizontal line
errorbar_colors = sorted["tendency"].map({-1: "red", 0: "gray", 1: "blue"})
plt.errorbar(sorted.index, sorted["Estimate"], yerr=sorted["Std.Error"], ecolor=errorbar_colors, capsize=0.5)
#plt.hlines(0, xmin=-1, xmax=len(sorted), colors='gray', linestyles='--')
#plt.scatter(sorted.index, sorted["Estimate"], c=sorted["tendency"].map({-1: "red", 0: "gray", 1: "blue"}))
plt.xticks(sorted.index, sorted["Hotel_Name"], rotation=45, ha='right')
plt.ylabel("Estimate")
plt.title("Time Effect by Hotel")

# Add text annotations
mean_pos = sorted["Pos"].mean()
mean_neg = sorted["Neg"].mean()
plt.text(x=len(sorted) + 0.5, y=0.1, s=f"Mean Pos: {mean_pos:.2f}", fontsize=12, color="blue")
plt.text(x=len(sorted) + 0.5, y=-0.1, s=f"Mean Neg: {mean_neg:.2f}", fontsize=12, color="red")

plt.show()

```


# Predictive performance

```{python}

from sklearn.metrics import mean_squared_error, mean_absolute_error



# In-sample predictions and error calculation
detection_data2 = detection_data.copy()  # Create a copy to avoid modifying original data
detection_data2['Estimate'] = model.predict(detection_data)

in_sample_rmse = np.sqrt(mean_squared_error(detection_data2['Reviewer_Score'], detection_data2['Estimate']))
in_sample_ame = mean_absolute_error(detection_data2['Reviewer_Score'], detection_data2['Estimate'])

print("In-sample:\nAbsolute Error:", in_sample_ame, "\nRMSE:", in_sample_rmse)

# Out-of-sample predictions and error calculation
test_data2 = test_data.copy()
test_data2['Estimate'] = model.predict(test_data)

out_sample_rmse = np.sqrt(mean_squared_error(test_data2['Reviewer_Score'], test_data2['Estimate']))
out_sample_ame = mean_absolute_error(test_data2['Reviewer_Score'], test_data2['Estimate'])

# Baseline model
baseline_rmse = np.sqrt(mean_squared_error(test_data['Reviewer_Score'], test_data['Average_Score']))
baseline_ame = mean_absolute_error(test_data['Reviewer_Score'], test_data['Average_Score'])

print("\nOut-of-sample:\nAbsolute Error:", out_sample_ame, "vs. Baseline:", baseline_ame, "\nRMSE:", out_sample_rmse, "vs. Baseline:", baseline_rmse)

```




```{python}
import seaborn as sns


# Calculate significance threshold
t_threshold = stats.t.ppf(0.40, df=model.df_resid)

# Determine significance and direction
time_effect_df["Pos"] = (time_effect_df["t_value"] > t_threshold).astype(int)
time_effect_df["Neg"] = (time_effect_df["t_value"] < -t_threshold).astype(int)
time_effect_df["tendency"] = time_effect_df["Pos"] - time_effect_df["Neg"]


# Calculate past average for each hotel
past_average = Hotel_Reviews[Hotel_Reviews['time_ref'] < 0].groupby('Hotel_Name')['Reviewer_Score'].mean().reset_index(name='past_average')

# Group test data by hotel and calculate mean review
grouped_test_data = test_data2.groupby('Hotel_Name')['Reviewer_Score'].mean().reset_index(name='mean_review')

# Join with time_effect_df and past_average
grouped_test_data = grouped_test_data.merge(time_effect_df, left_on='Hotel_Name', right_on='Hotel_Name')
grouped_test_data = grouped_test_data.merge(past_average, on='Hotel_Name')

# Calculate correct predictions
grouped_test_data['correct_neg'] = grouped_test_data['past_average'] > grouped_test_data['mean_review']
grouped_test_data['correct_pos'] = grouped_test_data['past_average'] < grouped_test_data['mean_review']

# Calculate proportions for negative and positive cases
proportion_data_neg = grouped_test_data.groupby(['Neg', 'correct_neg']).size().reset_index(name='m')
proportion_data_neg['proportion'] = proportion_data_neg['m'] / proportion_data_neg['m'].sum()

proportion_data_pos = grouped_test_data.groupby(['Pos', 'correct_pos']).size().reset_index(name='m')
proportion_data_pos['proportion'] = proportion_data_pos['m'] / proportion_data_pos['m'].sum()

# Calculate recall, precision, and F1-score for negative cases
true_positive_neg = proportion_data_neg[(proportion_data_neg['Neg'] == 1) & (proportion_data_neg['correct_neg'] == 1)]['m'].values[0]
false_negative_neg = proportion_data_neg[(proportion_data_neg['Neg'] == 0) & (proportion_data_neg['correct_neg'] == 1)]['m'].values[0]
false_positive_neg = proportion_data_neg[(proportion_data_neg['Neg'] == 1) & (proportion_data_neg['correct_neg'] == 0)]['m'].values[0]

recall_neg = true_positive_neg / (true_positive_neg + false_negative_neg)
precision_neg = true_positive_neg / (true_positive_neg + false_positive_neg)
f1_score_neg = 2 * (precision_neg * recall_neg) / (precision_neg + recall_neg)

# Calculate recall, precision, and F1-score for positive cases
true_positive_pos = proportion_data_pos[(proportion_data_pos['Pos'] == 1) & (proportion_data_pos['correct_pos'] == 1)]['m'].values[0]
false_negative_pos = proportion_data_pos[(proportion_data_pos['Pos'] == 0) & (proportion_data_pos['correct_pos'] == 1)]['m'].values[0]
false_positive_pos = proportion_data_pos[(proportion_data_pos['Pos'] == 1) & (proportion_data_pos['correct_pos'] == 0)]['m'].values[0]

recall_pos = true_positive_pos / (true_positive_pos + false_negative_pos)
precision_pos = true_positive_pos / (true_positive_pos + false_positive_pos)
f1_score_pos = 2 * (precision_pos * recall_pos) / (precision_pos + recall_pos)

# Plot the proportions
fig, axs = plt.subplots(1, 2, figsize=(12, 6))

sns.heatmap(proportion_data_neg.pivot_table(values='proportion', index='Neg', columns='correct_neg'), annot=True, fmt='.2f', cmap='coolwarm', ax=axs[0])
axs[0].set_title('Negative Cases')
axs[0].set_xlabel('Correct Negative')
axs[0].set_ylabel('Predicted Negative')
axs[0].text(0.5, 2.5, f'Recall: {recall_neg:.2f}\nPrecision: {precision_neg:.2f}\nF1-Score: {f1_score_neg:.2f}', ha='center', va='center')

sns.heatmap(proportion_data_pos.pivot_table(values='proportion', index='Pos', columns='correct_pos'), annot=True, fmt='.2f', cmap='coolwarm', ax=axs[1])
axs[1].set_title('Positive Cases')
axs[1].set_xlabel('Correct Positive')
axs[1].set_ylabel('Predicted Positive')
axs[1].text(0.5, 2.5, f'Recall: {recall_pos:.2f}\nPrecision: {precision_pos:.2f}\nF1-Score: {f1_score_pos:.2f}', ha='center', va='center')

plt.tight_layout()
plt.show()
```







```{r}

library(shiny)
library(DT)


test_window = expand.grid(Hotel_Name = unique(test_data$Hotel_Name), time_ref = seq(min(detection_data$time_ref), max(test_data$time_ref),0.2), Reviewer_Score2 =NA)
#detection_data2 = detection_data2 %>% mutate(Estimate = NA)
detection_data2 = detection_data2 %>% mutate(Reviewer_Score2 = Reviewer_Score)
test_window$Estimate = predict(fit, newdata = test_window)


plot_data = detection_data2

hotel_names <- unique(plot_data$Hotel_Name)
```

```{r}



# Define UI
ui <- fluidPage(
  mainPanel(
    selectInput("hotel", "Select Hotel:", choices = hotel_names),
    plotOutput("distPlot")
  )
)

# Define server logic
server <- function(input, output) {
  output$distPlot <- renderPlot({
    
    selected_hotel <- input$hotel
    
    # Filter data for the selected hotel
    filtered_data <- plot_data %>% filter(Hotel_Name == selected_hotel)
    
    
    # Check if the selected hotel has Neg == TRUE
    neg_hotel <- random_effct2 %>% filter(Name == selected_hotel & Neg == TRUE)

    
    # Plot
   p =  ggplot(filtered_data, aes(x = time_ref, y = Reviewer_Score2)) +
      geom_line(aes(y = Average_Score), color = "gray") +
      geom_point(aes(x = time_ref, y = Reviewer_Score2), alpha = 0.5) +
      geom_smooth(aes(x = time_ref, y = Reviewer_Score2), lty = "dashed") +
      geom_line(data= test_window  %>% filter(Hotel_Name == selected_hotel), aes(x=time_ref, y=Estimate)) +
      labs(title = "Predicted Reviewer Scores Over Time",
           x = "Date",
           y = "Predicted Reviewer Score") +
      coord_cartesian(ylim = c(6, 10)) + 
      theme_minimal() + 
      theme(legend.position = c(0.5, 0.9))
   if(random_effct2$Neg[random_effct2$Name == selected_hotel]==1)p =  p + geom_text(data = neg_hotel, aes(x = max(filtered_data$time_ref), y = 9, label = "!"), size = 10, color = "red", vjust = -1)
   if(random_effct2$Pos[random_effct2$Name == selected_hotel] ==1) p =  p + geom_text(data = neg_hotel, aes(x = max(filtered_data$time_ref), y = 9, label = "+"), size = 10, color = "green", vjust = -1)
   plot_grid(p,
   
   rbind(test_window  %>% filter(Hotel_Name == selected_hotel, time_ref > 0) %>% group_by(Hotel_Name) %>% summarise(pred = mean(Estimate), type="Prediction"),
   test_data  %>% filter(Hotel_Name == selected_hotel, time_ref > 0) %>% group_by(Hotel_Name) %>% summarise(pred = mean(Reviewer_Score), type="Vacation average"),
   Hotel_Reviews  %>% filter(Hotel_Name == selected_hotel, time_ref < 0) %>% group_by(Hotel_Name) %>% summarise(pred = mean(Reviewer_Score), type="Past average")) %>%
     ggplot(aes(x=type, y=pred)) + geom_bar(stat="identity") +      coord_cartesian(ylim = c(7, 10))  
   )


  })
}



shinyApp(ui = ui, server = server)

```


