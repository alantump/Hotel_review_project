{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.environ['OPENAI_API_KEY'] = <your-api-key>\n",
    "import openai\n",
    "import os\n",
    "\n",
    "api_key = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/langchain-ai/rag-from-scratch/blob/main/rag_from_scratch_5_to_9.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alan_\\AppData\\Local\\Temp\\ipykernel_30232\\278692378.py:22: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  Hotel_Reviews.loc[Hotel_Reviews[\"Hotel_Address\"].str.contains(pattern), \"Country\"] = country_name\n",
      "C:\\Users\\alan_\\AppData\\Local\\Temp\\ipykernel_30232\\278692378.py:22: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  Hotel_Reviews.loc[Hotel_Reviews[\"Hotel_Address\"].str.contains(pattern), \"Country\"] = country_name\n",
      "C:\\Users\\alan_\\AppData\\Local\\Temp\\ipykernel_30232\\278692378.py:22: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  Hotel_Reviews.loc[Hotel_Reviews[\"Hotel_Address\"].str.contains(pattern), \"Country\"] = country_name\n",
      "C:\\Users\\alan_\\AppData\\Local\\Temp\\ipykernel_30232\\278692378.py:22: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  Hotel_Reviews.loc[Hotel_Reviews[\"Hotel_Address\"].str.contains(pattern), \"Country\"] = country_name\n",
      "C:\\Users\\alan_\\AppData\\Local\\Temp\\ipykernel_30232\\278692378.py:22: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  Hotel_Reviews.loc[Hotel_Reviews[\"Hotel_Address\"].str.contains(pattern), \"Country\"] = country_name\n",
      "C:\\Users\\alan_\\AppData\\Local\\Temp\\ipykernel_30232\\278692378.py:22: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  Hotel_Reviews.loc[Hotel_Reviews[\"Hotel_Address\"].str.contains(pattern), \"Country\"] = country_name\n",
      "C:\\Users\\alan_\\AppData\\Local\\Temp\\ipykernel_30232\\278692378.py:22: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  Hotel_Reviews.loc[Hotel_Reviews[\"Hotel_Address\"].str.contains(pattern), \"Country\"] = country_name\n",
      "C:\\Users\\alan_\\AppData\\Local\\Temp\\ipykernel_30232\\278692378.py:22: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  Hotel_Reviews.loc[Hotel_Reviews[\"Hotel_Address\"].str.contains(pattern), \"Country\"] = country_name\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "def data_loader():\n",
    "  \"\"\"Loads data from CSV files, performs data cleaning and feature engineering.\n",
    "\n",
    "  Returns:\n",
    "    pandas.DataFrame: The processed hotel reviews dataset.\n",
    "  \"\"\"\n",
    "\n",
    "  # Read hotel reviews data\n",
    "  Hotel_Reviews = pd.read_csv(\"../Data/Hotel_Reviews.csv\")\n",
    "\n",
    "  # Read country data\n",
    "  countries = pd.read_csv(\"../Data/countries.csv\")\n",
    "\n",
    "  # Add a \"Country\" column with NA values\n",
    "  Hotel_Reviews[\"Country\"] = pd.NA\n",
    "\n",
    "  # Assign country based on pattern matching in Hotel_Address\n",
    "  for country_name in countries[\"name\"]:\n",
    "    pattern = re.compile(country_name, re.IGNORECASE)  # Case-insensitive matching\n",
    "    Hotel_Reviews.loc[Hotel_Reviews[\"Hotel_Address\"].str.contains(pattern), \"Country\"] = country_name\n",
    "\n",
    " \n",
    "  # Convert Review_Date to datetime and extract features\n",
    "  Hotel_Reviews[\"date_object\"] = pd.to_datetime(Hotel_Reviews[\"Review_Date\"], format=\"%m/%d/%Y\")\n",
    "  #Hotel_Reviews[\"time\"] = Hotel_Reviews[\"date_object\"].astype(int) / 10**9  # Convert to Unix timestamp\n",
    "  Hotel_Reviews[\"month\"] = Hotel_Reviews[\"date_object\"].dt.month\n",
    "  Hotel_Reviews[\"num_date_object\"] = Hotel_Reviews[\"date_object\"].dt.day_of_year / 365  # Normalize by days in a year\n",
    "\n",
    "  return Hotel_Reviews\n",
    "\n",
    "# Load the processed data\n",
    "Hotel_Reviews = data_loader()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### INDEXING ####\n",
    "\n",
    "# Load blog\n",
    "import bs4\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            class_=(\"post-content\", \"post-title\", \"post-header\")\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "blog_docs = loader.load()\n",
    "\n",
    "# Split\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=300, \n",
    "    chunk_overlap=50)\n",
    "\n",
    "# Make splits\n",
    "splits = text_splitter.split_documents(blog_docs)\n",
    "\n",
    "# Index\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "vectorstore = Chroma.from_documents(documents=splits, \n",
    "                                    embedding=OpenAIEmbeddings())\n",
    "\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "\n",
    "\n",
    "# Merge the columns using string concatenation\n",
    "Hotel_Reviews['MergedColumn_topic'] = (\n",
    "    Hotel_Reviews['Positive_Review'] + \n",
    "    '. ' + Hotel_Reviews['Negative_Review'] \n",
    ")\n",
    "# Select the first 100 rows of the merged column\n",
    "Hotel_Reviews_UK =Hotel_Reviews[Hotel_Reviews[\"Country\"]== \"United Kingdom\"]\n",
    "used_data = Hotel_Reviews_UK['Positive_Review']#Hotel_Reviews['MergedColumn_topic']#[:2000]\n",
    "\n",
    "# Specify the file name\n",
    "file_name = \"used_data.txt\"\n",
    "\n",
    "# Save the data to a text file\n",
    "with open(file_name, 'w') as f:\n",
    "    for line in used_data:\n",
    "        f.write(line + '\\n')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = used_data.tolist()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define get_embeddings Function: This function takes a text input, tokenizes it, passes it through the BERT model, and returns the mean of the last hidden state as the text's embedding.\n",
    "Define Topics and Keywords: It defines a dictionary of topics, each associated with a list of relevant keywords.\n",
    "Example Texts: It assumes docs[:5] contains example texts to be classified.\n",
    "Similarity Threshold: A threshold of 0.25 is set to determine if a text is similar enough to a topic.\n",
    "Classify Texts: For each text:\n",
    "It computes the embedding of the text.\n",
    "For each topic, it computes the average embedding of its keywords.\n",
    "It calculates the cosine similarity between the text's embedding and each topic's average keyword embedding.\n",
    "It assigns the text to topics where the similarity exceeds the threshold.\n",
    "Output: It prints the topics under which each text is classified or indicates if no topics match above the threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content='In the realm of code where logic flows,  \\nA curious creature delights and grows,  \\nIt dances through functions, a mystical kin,  \\nBehold! The magic of recursion begins.\\n\\nIn a forest of data, so vast and deep,  \\nWhere problems like mountains surround us, they creep,  \\nA clever solution hides under the trees,  \\nCalling itself, like a whispering breeze.\\n\\n\"To solve this conundrum,\" the wise coder spoke,  \\n\"I’ll break it in pieces, a plan I invoke!  \\nIf I know how to tackle the smaller, I vow,  \\nI’ll summon them back in a grand, graceful bow.\"\\n\\nSo here comes our function, with purpose so clear,  \\nIt checks for a base case, to silence our fear,  \\n“A simple condition, when true, will suffice,  \\nTo stop my recursion, to end this dice roll of dice.”\\n\\nBut if not, it calls, as if never to cease,  \\nThe same function again, in a dance of release,  \\nIt dives into depths, with each layer it peels,  \\nLike the rings of a tree, each call reveals.\\n\\nFrom the leaves of the problem, the answer takes flight,  \\nAs it builds up its structure, through day and through night,  \\nAnd finally, as echoes in caves start to blend,  \\nThe solution emerges, the journey’s sweet end.\\n\\nSo cherish this concept, both elegant, neat,  \\nWhere functions embrace in a recursive heartbeat,  \\nFor in the heart of programming’s enchanting domain,  \\nRecursion sings softly, a beautiful refrain.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "client = OpenAI(\n",
    "    api_key=os.environ.get(\"OPENAI_API_KEY\")\n",
    ")\n",
    "\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a poetic assistant, skilled in explaining complex programming concepts with creative flair.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Compose a poem that explains the concept of recursion in programming.\"}\n",
    "  ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextSummarizer:\n",
    "\n",
    "    # ChatGPT model that we will be using everywhere\n",
    "    openai_model = \"gpt-4o-mini\"\n",
    "\n",
    "\n",
    "    # Constructor    \n",
    "    def __init__(self):\n",
    "        self.apikey = self.fetch_api_key()\n",
    "\n",
    "\n",
    "    # Method to get API key\n",
    "    def fetch_api_key(self):\n",
    "        # In here would be all the code required to fetch the api key ...\n",
    "        return os.environ.get(\"OPENAI_API_KEY\")\n",
    "\n",
    "\n",
    "    # Method to take list of sentences and return summarized/average single sentence\n",
    "    def average_sentences(self, list_of_sentences):\n",
    "        # Instantiate the client\n",
    "        client = OpenAI(api_key=self.apikey)\n",
    "\n",
    "        # Write prompt to chatGPT to execute our task\n",
    "        prompt = \"Here is a list of multiple reviews that I want you to summarize and rewrite as a single review that is roughly the same length as the input reviews. The reviews are separated by newline characters \\n as follows: {sentences}\"\n",
    "        prompt = prompt.format(sentences = \"\\n\".join(list_of_sentences))\n",
    "\n",
    "        # Make request to chat GPT\n",
    "        completion = client.chat.completions.create(\n",
    "            model=self.openai_model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are an assistant that is able to read several reviews and then combine them into a single summarized review. The reviews will be sent to you with a newline character \\n separating them. You will return a single review.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        # Get the summarized sentence output from Chat GPT\n",
    "        summarized_sentence = completion.choices[0].message.content\n",
    "\n",
    "        # Close the client\n",
    "        client.close()\n",
    "\n",
    "        return summarized_sentence\n",
    "\n",
    "    # Method to summarize a piece of text\n",
    "    def summarize_text(self, input_text):\n",
    "        # Instantiate the client\n",
    "        client = OpenAI(api_key=self.apikey)\n",
    "\n",
    "\n",
    "        # Make request to chat GPT\n",
    "        completion = client.chat.completions.create(\n",
    "            model=self.openai_model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are an assistant that is able to read a piece of text and summarize it. Your summary will be 4 sentences or less.\"},\n",
    "                {\"role\": \"user\", \"content\": \"Here is the text to be summarized below the newline character.\\n {text}\".format(text=input_text)}\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        # Get the summary of the inptu text output from Chat GPT\n",
    "        summary_output = completion.choices[0].message.content\n",
    "\n",
    "        # Close the client\n",
    "        client.close()\n",
    "\n",
    "        return summary_output        \n",
    "    \n",
    "    \n",
    "    # Method to summarize a piece of text\n",
    "    def summarize_text_topic(self, input_text):\n",
    "        # Instantiate the client\n",
    "        client = OpenAI(api_key=self.apikey)\n",
    "\n",
    "\n",
    "        # Make request to chat GPT\n",
    "        completion = client.chat.completions.create(\n",
    "            model=self.openai_model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"\"\"You are an assistant that is able to read a piece of text and summarize it. Please provide a one sentence general summary.\n",
    "                 Additionally you will write  a summary sentence on each of the for topics: Room, Food and Drinks, Location, Internet and Work and Surprise.\n",
    "                 Here are some keywords for each topic \n",
    "                \"Room\": [\"room\", \"rooms\", \"upgrade\", \"clean\", \"tidy\", \"large\", \"bathroom\", \"bed\", \"TV\", \"shower\"] all aspects of describing the status of the room,\n",
    "                \"Food and Drinks\": [\"drinks\", \"cocktails\", \"bottle\", \"breakfirst\", \"dinner\", \"menu\", \"caffee\", \"tee\", \"delicious\", \"continental\", \"waiter\",\"restaurant \"] all aspects describing the quality of food like breakfirst and bar,\n",
    "                \"Location\": [\"close\", \"far\", \"next\", \"park\", \"train\", \"bicicle\", \"car\", \"walk\", \"tee\", \"building\", \"neighborhood\", \"cab service\", \"airport\", \"subway\", \"stairs\"] all aspects describing the location, surrounding and connection of the hotel,\n",
    "                \"Internet and Work\": [\"wifi\", \"Internet\", \"connection\", \"work\", \"password\", \"computer\", \"meeting\", \"signal\"] all aspects describing abilty to work from the hotel with a focus on internet connection,\n",
    "                \"Surprise\": [\"everything\", \"honestly\", \"surprising\", \"change\", \"unfortunately\", \"refund\"] all aspects which are supringly and not expected by the reviewer,\n",
    "                Feel free to say that the reviews do not specifically address certain topics.\n",
    "                 \"\"\"},\n",
    "                {\"role\": \"user\", \"content\": \"Here is the text to be summarized below the newline character.\\n {text}\".format(text=input_text)}\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        # Get the summary of the inptu text output from Chat GPT\n",
    "        summary_output = completion.choices[0].message.content\n",
    "\n",
    "        # Close the client\n",
    "        client.close()\n",
    "\n",
    "        return summary_output    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This hotel offers a very comfortable stay with cozy beds and pleasant facilities, including a lovely garden that’s perfect for summer evenings. The staff is friendly and exceptionally helpful, particularly in organizing daytime activities. Located in a quiet area, it provides great access to public transportation, making it easy to explore nearby restaurants and shops. While the bathrooms could use some ventilation, and the rooms are on the smaller side, the overall experience is enjoyable. The hotel also serves a delightful breakfast and has a laundrette conveniently located nearby for longer stays. Overall, it’s a great value for London, and I would definitely recommend staying here again.\n"
     ]
    }
   ],
   "source": [
    "gpt_summarizer = TextSummarizer()\n",
    "avg_sentence = gpt_summarizer.average_sentences(docs[:5])\n",
    "\n",
    "print(avg_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The hotel is praised for its comfortable beds, friendly staff, and lovely garden facilities, with a quiet location that's close to public transport and local eateries. Guests appreciate the helpfulness of the staff and the bonus of a laundrette nearby for long-term travelers. While some noted the older facilities and small bathrooms, the overall experience is seen as a great value for London, with many indicating they would stay again.\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarized_output_text = gpt_summarizer.summarize_text(docs[:5])\n",
    "summarized_output_text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall, the reviews highlight a comfortable stay with friendly staff, a well-located hotel near public transport and restaurants, and some minor issues with room size and bathroom ventilation.\n",
      "\n",
      "**Room:** The rooms are described as small but clean and comfortable, with good showers, although the bathrooms may lack ventilation.\n",
      "\n",
      "**Food and Drinks:** The hotel offers a good breakfast and is near many restaurants, providing a variety of dining options within walking distance.\n",
      "\n",
      "**Location:** The hotel is in a quiet area with great access to public transport, particularly near the subway, making it convenient for exploring the city and reaching the airport.\n",
      "\n",
      "**Internet and Work:** The reviews do not specifically address internet connectivity or work facilities, suggesting it may not be a focus for guests.\n",
      "\n",
      "**Surprise:** Reviews indicate positive surprises with the property, such as lovely facilities like the garden, friendly and accommodating staff, and overall good value for the London area.\n"
     ]
    }
   ],
   "source": [
    "gpt_summarizer = TextSummarizer()\n",
    "summarized_output_text = gpt_summarizer.summarize_text_topic(docs[:5])\n",
    "print(summarized_output_text) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Collective_LLM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
