{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.environ['OPENAI_API_KEY'] = <your-api-key>\n",
    "import openai\n",
    "import os\n",
    "\n",
    "api_key = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/langchain-ai/rag-from-scratch/blob/main/rag_from_scratch_5_to_9.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alan_\\AppData\\Local\\Temp\\ipykernel_36492\\278692378.py:22: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  Hotel_Reviews.loc[Hotel_Reviews[\"Hotel_Address\"].str.contains(pattern), \"Country\"] = country_name\n",
      "C:\\Users\\alan_\\AppData\\Local\\Temp\\ipykernel_36492\\278692378.py:22: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  Hotel_Reviews.loc[Hotel_Reviews[\"Hotel_Address\"].str.contains(pattern), \"Country\"] = country_name\n",
      "C:\\Users\\alan_\\AppData\\Local\\Temp\\ipykernel_36492\\278692378.py:22: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  Hotel_Reviews.loc[Hotel_Reviews[\"Hotel_Address\"].str.contains(pattern), \"Country\"] = country_name\n",
      "C:\\Users\\alan_\\AppData\\Local\\Temp\\ipykernel_36492\\278692378.py:22: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  Hotel_Reviews.loc[Hotel_Reviews[\"Hotel_Address\"].str.contains(pattern), \"Country\"] = country_name\n",
      "C:\\Users\\alan_\\AppData\\Local\\Temp\\ipykernel_36492\\278692378.py:22: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  Hotel_Reviews.loc[Hotel_Reviews[\"Hotel_Address\"].str.contains(pattern), \"Country\"] = country_name\n",
      "C:\\Users\\alan_\\AppData\\Local\\Temp\\ipykernel_36492\\278692378.py:22: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  Hotel_Reviews.loc[Hotel_Reviews[\"Hotel_Address\"].str.contains(pattern), \"Country\"] = country_name\n",
      "C:\\Users\\alan_\\AppData\\Local\\Temp\\ipykernel_36492\\278692378.py:22: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  Hotel_Reviews.loc[Hotel_Reviews[\"Hotel_Address\"].str.contains(pattern), \"Country\"] = country_name\n",
      "C:\\Users\\alan_\\AppData\\Local\\Temp\\ipykernel_36492\\278692378.py:22: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  Hotel_Reviews.loc[Hotel_Reviews[\"Hotel_Address\"].str.contains(pattern), \"Country\"] = country_name\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "def data_loader():\n",
    "  \"\"\"Loads data from CSV files, performs data cleaning and feature engineering.\n",
    "\n",
    "  Returns:\n",
    "    pandas.DataFrame: The processed hotel reviews dataset.\n",
    "  \"\"\"\n",
    "\n",
    "  # Read hotel reviews data\n",
    "  Hotel_Reviews = pd.read_csv(\"../Data/Hotel_Reviews.csv\")\n",
    "\n",
    "  # Read country data\n",
    "  countries = pd.read_csv(\"../Data/countries.csv\")\n",
    "\n",
    "  # Add a \"Country\" column with NA values\n",
    "  Hotel_Reviews[\"Country\"] = pd.NA\n",
    "\n",
    "  # Assign country based on pattern matching in Hotel_Address\n",
    "  for country_name in countries[\"name\"]:\n",
    "    pattern = re.compile(country_name, re.IGNORECASE)  # Case-insensitive matching\n",
    "    Hotel_Reviews.loc[Hotel_Reviews[\"Hotel_Address\"].str.contains(pattern), \"Country\"] = country_name\n",
    "\n",
    " \n",
    "  # Convert Review_Date to datetime and extract features\n",
    "  Hotel_Reviews[\"date_object\"] = pd.to_datetime(Hotel_Reviews[\"Review_Date\"], format=\"%m/%d/%Y\")\n",
    "  #Hotel_Reviews[\"time\"] = Hotel_Reviews[\"date_object\"].astype(int) / 10**9  # Convert to Unix timestamp\n",
    "  Hotel_Reviews[\"month\"] = Hotel_Reviews[\"date_object\"].dt.month\n",
    "  Hotel_Reviews[\"num_date_object\"] = Hotel_Reviews[\"date_object\"].dt.day_of_year / 365  # Normalize by days in a year\n",
    "\n",
    "  return Hotel_Reviews\n",
    "\n",
    "# Load the processed data\n",
    "Hotel_Reviews = data_loader()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### INDEXING ####\n",
    "\n",
    "# Load blog\n",
    "import bs4\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            class_=(\"post-content\", \"post-title\", \"post-header\")\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "blog_docs = loader.load()\n",
    "\n",
    "# Split\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=300, \n",
    "    chunk_overlap=50)\n",
    "\n",
    "# Make splits\n",
    "splits = text_splitter.split_documents(blog_docs)\n",
    "\n",
    "# Index\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "vectorstore = Chroma.from_documents(documents=splits, \n",
    "                                    embedding=OpenAIEmbeddings())\n",
    "\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "\n",
    "\n",
    "# Merge the columns using string concatenation\n",
    "Hotel_Reviews['MergedColumn'] = (\n",
    "     '' +'Hotel: ' + Hotel_Reviews['Hotel_Name'] + \n",
    "    '. Guest Review: ' + Hotel_Reviews['Positive_Review'] + \n",
    "    '. ' + Hotel_Reviews['Negative_Review'] + \"\\n\"\n",
    ")\n",
    "# Select the first 100 rows of the merged column\n",
    "used_data = Hotel_Reviews['MergedColumn'][:100]\n",
    "\n",
    "# Specify the file name\n",
    "file_name = \"used_data.txt\"\n",
    "\n",
    "# Save the data to a text file\n",
    "with open(file_name, 'w') as f:\n",
    "    for line in used_data:\n",
    "        f.write(line + '\\n')\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "raw_documents = TextLoader('used_data.txt').load()\n",
    "\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    separators=[\"\\n\\n\"],\n",
    "    chunk_size=300, \n",
    "    chunk_overlap=50)\n",
    "\n",
    "\n",
    "splits = text_splitter.split_documents(raw_documents)\n",
    "\n",
    "embeddingsAI = OpenAIEmbeddings()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Index\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "folder_path = \"./chroma_db_reviews_crete_merged\"\n",
    "if not os.path.exists(folder_path):\n",
    "    vectorstore = Chroma.from_documents(documents=splits, \n",
    "                                    embedding=embeddingsAI,persist_directory=folder_path)\n",
    "else:\n",
    "    vectorstore = Chroma(persist_directory=folder_path,embedding_function=embeddingsAI)\n",
    "\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "# Multi Query: Different Perspectives\n",
    "template = \"\"\"You are an AI language model assistant. Your task is to generate five \n",
    "different versions of the given user question to retrieve relevant documents from a vector \n",
    "database. By generating multiple perspectives on the user question, your goal is to help\n",
    "the user overcome some of the limitations of the distance-based similarity search. \n",
    "Provide these alternative questions separated by newlines. Please answer the question and provide a summary of the review your answer is based on. Original question: {question}\"\"\"\n",
    "prompt_perspectives = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "generate_queries = (\n",
    "    prompt_perspectives \n",
    "    | ChatOpenAI(temperature=0) \n",
    "    | StrOutputParser() \n",
    "    | (lambda x: x.split(\"\\n\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alan_\\AppData\\Local\\Temp\\ipykernel_36492\\1524860966.py:10: LangChainBetaWarning: The function `loads` is in beta. It is actively being worked on, so the API may change.\n",
      "  return [loads(doc) for doc in unique_docs]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.load import dumps, loads\n",
    "\n",
    "def get_unique_union(documents: list[list]):\n",
    "    \"\"\" Unique union of retrieved docs \"\"\"\n",
    "    # Flatten list of lists, and convert each Document to string\n",
    "    flattened_docs = [dumps(doc) for sublist in documents for doc in sublist]\n",
    "    # Get unique documents\n",
    "    unique_docs = list(set(flattened_docs))\n",
    "    # Return\n",
    "    return [loads(doc) for doc in unique_docs]\n",
    "\n",
    "# Retrieve\n",
    "question = \"Does the Hilton Vienna have good Wifi in the room?\"\n",
    "retrieval_chain = generate_queries | retriever.map() | get_unique_union\n",
    "docs = retrieval_chain.invoke({\"question\":question})\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided context, there is no mention of the Hilton Vienna hotel. Therefore, it is not possible to determine if the Hilton Vienna has good Wifi in the room.\n"
     ]
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "# RAG\n",
    "template = \"\"\"Answer the following question based on this context:\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "llm = ChatOpenAI(temperature=0)\n",
    "\n",
    "final_rag_chain = (\n",
    "    {\"context\": retrieval_chain, \n",
    "     \"question\": itemgetter(\"question\")} \n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "print(final_rag_chain.invoke({\"question\":question}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Collective_LLM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
